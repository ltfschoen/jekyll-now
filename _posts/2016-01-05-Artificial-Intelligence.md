---
layout: post
title: Artificial Intelligence Nanodegree (in progress!)
---

# Table of Contents
  * [Chapter 1 - Artificial Intelligence Nanodegree](#chapter-1)
  
## Chapter 1 - Artificial Intelligence<a id="chapter-1"></a>

### Background and Definition

* AI comprises design and building intelligent entities/agents and requires
    * Intelligence
    * Artifact (i.e. computer)
* AI methods concern:
    * Human Thinking Automation (i.e. decision-making, problem solving, learning)
        * Cognitive Science Modelling Approach
            * Build precise and testable theory to express as 
            computer program algorithm AI models
            with matching input/output behaviour including 
            trace of reasoning steps when solving problems 
            comparable to human performance (similar to General Problem Solver of 
            1961), using:
                * Introspection (i.e. of human thoughts)
                * Psychological Experiments (i.e. observe human action)
                * Brain Imaging (i.e. observe brain action, incorporating
                neurophysiological evidence into computer models)
    * Mental Computation Models (i.e. perception, reasoning, action)
    * Behaviour
* AI measures success against:
    * Human Intelligence Performance Comparison (i.e. Turing Test 
    to see if can decipher whether response by human or computer
    using Computer Vision  and Robotics for object perception/manipulation)
        * Computer Capabilities
            * Natural Language Processing (i.e. communicates in English)
            * Knowledge Representation (i.e. store current knowledge, store received/heard info)
            * Automated Reasoning (i.e. reason and respond to requests using stored data)
            * Machine Learning (i.e. adapt to new situations and detect/deal with patterns)
    * Rationality (i.e. ideal performance with given data and assumptions)
        * THOUGHT - Logic Notation (discovered by Aristotle) by reasoning with
        statements about any object and relationships between
        with guidance on reasoning steps to try first to minimise computational 
        resources to solve problems in "principle" using 
        Intelligent Computational Reasoning Systems 
        (differs from solving in "practice")
        * ACTION (by rational agent) - 
            * Autonomous operation
            * Perception of environment
            * Adapt to change
            * Uptime maintained
            * Goal pursuit
            * Deliver best outcome/decision 
            * Rationality using inference given uncertainy (using 
            Knowledge Representation)
* AI approach to:
    * Simple Probems
        * Hypothesis that perfect rationality required for analysis
    * Complex Problems
        * Realise that unable to achieve perfect rationality requiring
         high computational demands 
* Definitions (of Mind and Matter)
    * Rationalism - Reasoning to understand the world
    * Dualism - Human mind has dual qualities governed by 
    both soul/spiritual laws and physical laws
    * Materialism - Human mind is constituted from brain operation
    according to laws of physics
    * Empirism
        * Flow of Knowledge 
            * Source of Knowledge
            * Physical mind uses Senses to manipulate Knowledge with 
            reasoning to achieve Understanding
    * Logical Positivism (Doctrine) - Combines Rationalism and Empiricism
    whereby Knowledge arises from interconnected logical theories connected
    to Observation Sentences corresponding to Sensory Inputs
    * Free will - Perception of choices to a choosing entity
    * Induction Principle - Senses are reliant on rules (Confirmation Theory)
    when acquiring Knowledge from their Experience 
    (exposure to repeated associations between elements)
    * Actions (occur after Reasoning) - Actions justified through
    logical connection between Goals, and Knowledge of an Action's 
    outcome (assuming the possible end outcome based on Experience)
* Rational Decision Theory
    * Issues
        * Decision-making Rules when several Actions achieve same Goal
        * Decision-making Rules when no Action achieves Goal
        * Decision-making Rules when uncertainty
    * AI Science
        * Maths (areas contributing to AI)
            * Logic
                * Algorithms using maths reasoning for logical deduction.
                Procedure to prove any true statement in boolean
                first-order logic of objects and relations,
                but first-order logic does not capture principle of maths
                induction required to characterise natural numbers.
                Incompleteness Theorem proved that in arithmetic (elementary
                natural numbers) some true statements are undecidable 
                (no proof within the theory), whereby some functions on
                integers cannot be represented by an algoritm.
                * Turing Machine was developed and showed some functions
                could not be Computed
                * Theory of References related logic objects with 
                real-world objects
            * Computation
                * **Tractability** - (easy) problems where time required to solve instance of
                problem grows with Polynomial growth.
                Tractable sub-problems should be approached when generating
                intelligent behaviour 
                    * Polynomial growth
                * **Intractable** (hard) problems - time required to solve instance of 
                problem grows Exponentially with size of instances
                * **Exponential growth** in complexity means even moderately
                large problem instances cannot be solved in reasonable timeframe
                * **NP-completeness Theory** showed there are many
                NP-complete problems (combination of search and
                reasoning), such that if a given problem class may be reduced to 
                one of these NP-complete problems, it is likely Intractable
            * Probability
                * Quantitative Science 
                    * Bayes' Rule used for uncertain measurements/reasoning
                    of AI systems. Statistical methods used to overcome
                    incomplete theories
        * Science
            * Economics
                * Definitions:
                    * Economies comprise individual agents making choices
                    that lead to preferred outcomes that maximise
                    economic well-being
                    * Sellers may assert they prefer money whilst they hope 
                    Buyers prefer their goods
                * Large Economies
                    * Decision Theory 
                    (framework for decisions under uncertain environment)
                        * Probability Theory
                        * Utility Theory
                        * **Usage**: Suitable for large economies where individual 
                        agents should not be concerned about Actions undertaken 
                        jointly by multiple other agents
                * Small Economies
                    * Game Theory
                        * **Usage**: Suitable for small economies where individual agents
                        may be significantly affected by Actions of other individual agents
                        * **Note**: Discovered that rational agents should appear to adopt
                        random policies (ambiguous prescription for Actions)
                * Other
                    * Satisficing
                        * Definition: "Good enough" decisions rather than optimally
                        calculated decisions more accurately describe human behaviour 
                    * Optimisation of Sequence Operations
                        * Definition: Rational agent decisions when multiple Actions in 
                        sequence result in payoff
            * Neuroscience
                * Brain
                    * Thought, Action, Consciousness enables Minds - 
                    based on collection of neurons
                        * Mysticism Theory - Alternative theory whereby mind operates in
                        mystical realmn beyond physical science
                    * Cognitive Functions Segregated
                        * Speech production (left hemisphere)
                    * Neuronal Structure
                        * Electrochemical signals sent via neuron 
                        junctions to control brain activity and learning
                        * Information processing in outer layer of brain
                        using tunnels of tissue 0.5mm dia / 4.0mm depth 
                        containing 20,000 neurons
                        * **Unknown** is how damaged functions adopted by others
                        * **Unknown** is how individual memory stored
                        * Note: Single-cell neuron activity artificially stimulated 
                        (electrically, chemically, optically) for recording
                        of neuron I/O mapping relating to cognitive processes
                    * Sensory Signals
                        * Publish/Subscribe mapping between brain areas
                        and bodily parts (control output or sensory input 
                        received)
                        * Note: Multiple maps apparent in some creatures
                        that change every few weeks
                        * Note: Brain activity images using EEG and MRI
                * Research Applications
                    * Math Models applied to nerve cells (neurons) 
                    to study nervous system
            * Psychology
                * Behaviourism
                    * Achievements: Discoveries in some animals but less with humans
                    * Human Behaviour Experiments
                        * Subjective methodology 
                            * Introspective data is subjective 
                            (unlikely experimenter disagree with own theory)
                        * Note: Objective methodology applied to humans
                    * Animal Behaviour Experiments
                        * Objective measures of stimulus given and resulting actions/response
                            * Lack of introspective data
                * Cognitive Psychology
                    * Definition: Brain viewed as a CPU
                    * Knowledge-based Agent Info Processing Steps
                        * Translate stimulus to internal representation
                        * Manipulate internal representation using 
                        Cognitive Processes to achieve new internal
                        representation
                        * Translate back into Action
                * Computer Models should be like Cognitive Theory and
                address psychology of the following by describing information
                processing mechanism for cognitive function implementation:
                    * Memory 
                    * Language
                    * Logical Thought
            * Computer Engineering
                * Future power increases from mass parallelism
                * AI work has pioneered ideas used in computer science
                (i.e. object-oriented programming, etc)
            * Control Theory and Cybernetics
                * Control Theory Tools
                    * Calculus
                    * Matrix Algebra
                * Control Theory Systems
                    * Systems described by "fixed" sets of continous variables
                * Artifact (computer) Systems
                    * Self-regulating feedback control system machines (modify behaviour in response
                    to env changes). i.e. submarine, thermostat
                * AI
                    * Escapes limitations (NOT "fixed")
                    * Logical Inference and Computation Tools solve problems in:
                        * Language
                        * Vision
                        * Planning
                * Purposive Behaviour
                    * Regulatory mechanism that minimises error toward goal state
                * Intelligence AI Source
                    * Homeostatic devices with feedback loops creating stable
                    adaptive behaviour
                * Stochastic Optimal Control
                    * Goal of system designs that behave optimally 
                    (maximising objective function over time)
            * Linguistics
                * Behaviourist Approach - to Language Learning
                    * Ignores Creativity in language (i.e. child makes sentences)
                * Syntactic Structures & Chomsky's Theory
                * Natural Language Processing (aka Computational Linguistics)
                    * Understand sentence structures, subject matter, and context 
                    to understand a language and use Knowledge Representation to convert
                    into form a computer may reason with
                    
### History of AI

up to page 18



## Python Links

* Python `zip, map, lambda` https://bradmontgomery.net/blog/pythons-zip-map-and-lambda/
* Iterate Dictionary/Hash: `for k, v in values.items():`
* Iterate Array: `for val,i in enumerate(range(len(a))):`
http://www.diveintopython.net/file_handling/for_loops.html
                    `values[val]`
* Iterate over String: `[i for i in k]`
* Append to Array: `elim_box.append((k, v))`
* Replace values in string: `removed = original.replace("M", "")`
http://www.petercollingridge.co.uk/book/export/html/362

## Extra Curricular

### Code links

* AIMA textbook example algorithms https://github.com/aimacode/aima-python
    * lecture 6 (right ahead of project 2) and from AIMA only had to cover 5.1-5.4 specifically references DFS and iterative deepening from earlier chapters
* Github projects

https://github.com/udacity?utf8=%E2%9C%93&q=aind
https://github.com/udacity/artificial-intelligence
https://github.com/danainschool/aima-python
https://github.com/udacity/AIND-Isolation
https://github.com/udacity/AIND-Planning
https://github.com/ltfschoen/AIND-Sudoku
https://github.com/ltfschoen/hmmlearn

### Python requirements

* itertools, list comprehensions, tuples, function with multiple return values, default values as function params, functions as first class citizen (pass functions like variables), creating classes
* Anaconda
* Python 3
* Courses preparation https://www.udacity.com/course/design-of-computer-programs--cs212

### OpenAI

https://github.com/openai
https://openai.com/blog/

### Research Papers in AI

https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap
https://github.com/terryum/awesome-deep-learning-papers?files=1
http://www.arxiv-sanity.com/
* Summaries already done https://docs.google.com/spreadsheets/d/1xej5Nca2xUUtrZ1GCyPjFMqI9ZgNq_OhgnTxOOMQ2js/edit#gid=404493967
* DL related (Jack Clark at OpenAI to crowdsource via dhruvp): https://docs.google.com/spreadsheets/d/1MT8LRuEn3xdJ7j6_XQjRZwV_fRmrpjaWwZKGk2Dqm4k/edit#gid=0

### Competitions in AI
* General AI Challenge

https://www.general-ai-challenge.org/active-rounds
https://discourse.general-ai-challenge.org/

### Convert Markdown to PDF
* https://gitprint.com/

### Reading - Python

* Book "Data structures and algorithms in Python"
    * Recursion chapter, Tree/graph algorithms
* Official Python Docs - itertools and other Python packages
* AI Overview 
    * DARPA https://youtu.be/-O01G3tSYpU
* AIMA book
    * Chapters http://aima.cs.berkeley.edu/2nd-ed/newchap11.pdf
    * Code examples for each of the algorithms https://github.com/aimacode
* Python e-books:
http://www.diveintopython3.net
https://learnpythonthehardway.org/book/
http://www.deeplearningbook.org/

* MIT AI course (similar topics to AIND) https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/

## Week 0
* Kick-off event https://youtu.be/z7V7Ri6P_dA
* About
https://www.udacity.com/course/artificial-intelligence-nanodegree--nd889

## Week 1
* Guides
    * Sebastian Thrun - Udacity co-founder
        * Key takeaways:
          - Reinforces that AI surpassing human efficiency for repetitive tasks
          - Highlights self-driving car applications, benefits (i.e. safety), and modern suppliers
          - Identifies need for multi-tasking AI platform
          - Suggests students to build innovative experiments and forward to Sebastian (i.e. using Arduino)
    * Peter Norvig - Google - AI book author
    * Thad Starner - Georgia Tech - Contextual Computing & Google X researcher
    * Arpan Chakraborty - Georgia Tech - Computer Vision - AI research
    * David Joyner - Georgia Tech - AI lecturer - applies AI to tools
    * Dhruv Parthasarathy - AI Program director
    * Lisbeth Ortega - Community Manager
    * Kathleen Mullaney - Career Services
    * Rachel Higgens - Career Services
    * Trinh Nguyen - Career Services - Program Coordinator
    * Kirsten Bailer - Career Services - Employer Relations
    * Luis Serrano - Instructor/Course Developer
    * Dean Webb - Mentor Online
    * Shelly - provides Quizzes during course
    * Help: ai-support@udacity.com OR Chris LaPollo (outside enrolment)

* Project 1 - Sukoku AI-agent
    * Build and code AI-agent solves any Sudoku problem
        * Learn 2x AI techniques
            * Constraint Propagation
            * Search
        * Advanced Sukoku strategy to improve agent speed
    * Based on blogpost http://norvig.com/sudoku.html

* Project 2 - Game playing AI-agent
    * AI-agent plays games and defeats opponents in isolation
        * Learn 2x AI Strategies (used by Google's Go agent AlphaGo)
            * Minimax
            * Alpha-beta pruning
    * AI-agent guides pacman through maze faster and eats food efficiently
        * Learn 2x AI strategies
            * Breadth-first search
            * Depth-first search
            * A-Start search
* Project 3 - Planning AI-agent          
    * AI-agent plans optimal route transport cargo from A to B (used in logistics)
* Project 4 - Natural Language Processing ??? AI-agent
    * AI-agent automatically reads sign language chars and convert to English
        * Learn 1x AI strategy
            * Hidden Markov Models

* Deadlines
    * Deadline means submitted and Reviewed
* Code Reviews - Unlimited
* Mentor - Leadership, Guidance, SME
    * Weekly checkin so track.
    * Help set learning goals.
    * Guide to supplementary resources when get stuck
    * Respond to any questions about the program
* Office Hours https://calendar.google.com/calendar/embed?src=knowlabs.com_h7k8bibekume01f054v7ns8v1o%40group.calendar.google.com
    * instructors, content creators and other Udacity staff to answer questions about the content and projects
* Forums - Tech Ques https://discussions.udacity.com/
    * AIND Term 1 Categories - https://discussions.udacity.com/categories
        * **Projects** category – post anything specific to projects in respective sub-categories there
        * **Announcements** specific to cohort including reminders and additional resources
        * **Cafe** interact with your peers
* Community - Online/Offline Study Groups arranged by Udacity 
* Career Services - http://career-resource-center.udacity.com
    * Udacity partners
        * Google, IBM Watson, Accenture, AT&T, Priceline.com, Nvidia, Mercedes-Benz, Amazon
    * Career Path - Location, etc
    * Career Development in Classroom
        * Resume updates
        * Udacity Reviews for free
* Other Students -
    * Sample Search https://www.google.com.au/webhp?sourceid=chrome-instant&ion=1&espv=2&ie=UTF-8#q=code+solution+naked+twins+sudoku+aind+github
    * Solution to Sudoku Naked Twins - https://github.com/vxy10/AIND-Sudoku/blob/master/solution.py
    * https://github.com/Kiyo921/AI-sudoku
    * Project 2
        * https://github.com/philferriere/aind-projects
        * https://github.com/bdiesel?tab=repositories
        * https://github.com/ziyanfeng/AIND-Isolation
        * https://github.com/davidventuri/udacity-aind
        * https://github.com/mohankarthik?tab=repositories
        * https://github.com/mohankarthik/AIND-P2-Isolation
        * https://github.com/mohankarthik/AIND-L1-Pacman
        * https://github.com/mlgill?tab=repositories
        * https://github.com/mlgill/AIND-Isolation
        * https://github.com/mlgill/AIND-Planning
        * https://github.com/mlgill/AIND-Simulated_Annealing
        * https://github.com/morganel?tab=repositories
        * https://github.com/morganel/AIND-Isolation-1
        * https://github.com/morganel/AIND-Planning

* Chat - Slack https://artificial-intelligence.udacity.com/
    * ai-nd.slack.com
    * LinkedIn Links https://docs.google.com/spreadsheets/d/1kdiF8weRpmaF91xqmeZ27tqf7IPgWqhpYxeynDb--SA/edit#gid=0
        * Intro
        @channel Hello everyone. My name is Mike Salem and I am the Nanodegree Service Lead for AI. I want to welcome each and every one of you to Artificial Intelligence!
        
        For introductions:
        1. Your name (first name is OK)
        2. Where are you from / located
        3. What's your background / have you taken any AI courses in the past?
        4. Why did you sign up for the AIND? What would you like to learn?
        5. (Optional) Do you have any cool AI related things you would like to show off? be creative. 
        It could be a github account, a youtube videos, etc.
        
        We want your experience at Udacity to be the best possible. So please chat with other people in the channel, make friends, and most importantly learn and have fun!
* Bug Reporting https://waffle.io/udacity/aind-issue-reports

* IntelliJ Python Debugger Setup

Find Miniconda Python:
$ which python
/Users/Ls/miniconda3/bin/python

File > Project Structure > Platform Settings > SDKs > + > Python SDK > /Users/Ls/miniconda3/bin/python

File > Project Settings > Project > Project SDK > Python 3.6.0 (~/miniconda3/bin/python...)

Run > Debug > + > Python
- Name: Sudoku
- Script: /Users/Ls/code/aind/term01/lesson01/function.py
- Use Specified Interpreter: Python 3.6.0 (~/miniconda3/bin/python...)

* Lesson 1 - Anaconda
    * About - Version management (specifically built for data science)
    * About Conda
        * Dfn (Conda) - Package manager (install library/software) and Virtual Environment manager (similar to `virtualenv` and `pyenv`)
            * Note: `pip` is the default Python package manager (general packages)
            * Note: `conda` is Python package manager (focus on data science packages), not specific to just Python packages
        * Dfn (Anaconda) - Large software distribution that comes with Conda, python, and 150 scientific packages (data science) and dependencies
            * i.e. comes with: Numpy, Scipy and Scikit-learn compiled with the MKL library, speeding up various math operations
        * Dfn (Miniconda) - Small software distributin comes with Conda, python (install required packages manually)
    * Usage of Conda
        * Conda Documentation https://conda.io/docs/using/index.html
        * Cheat Sheet https://conda.io/docs/_downloads/conda-cheatsheet.pdf
        * Cheat Sheet Advanced http://know.continuum.io/rs/387-XNW-688/images/conda-cheatsheet.pdf?mkt_tok=eyJpIjoiWm1Sak56UmpZMlZsTW1aaSIsInQiOiJOc3Rud2NraTI4ODlzVmJBSnllZ0JJWk1ZSlhLbE5QOEhZUWRMMDY2NWUrNGZxalRnSXNcL2NOM3h2UVFJN0ZJV0YybGpGOFNrdEJWa0Rnd1hlRnFzXC9wdUJcL1c1bkxsWVZIT1JzXC9vRGwwSmNvREpGXC9UYk9LV01UcjV6b1Z3TlN2In0%3D
        * Another https://leifengtechblog.files.wordpress.com/2016/01/conda-cheatsheet.pdf
        * Steps
            * Create new environement for each project (separate package versions so no version conflicts)
                `conda create -n tea_facts python 3`
            * Delete env
                `conda remove -n tea_facts --all` (or `conda env remove -n tea_facts`)
            * Activiate environment
                `source activate tea_facts`
            * Deactivate environment
                `source deactivate tea_facts`
            * Show default packages installed
                `conda list`
            * Show non-Python packages
                `conda search --canonical  | grep -v 'py\d\d'`
            * Update environment with new packages (i.e. work with t-data, visualisations, code development)
                `conda install numpy pandas matplotlib`
                `conda install jupyter notebook`
            * Update a package
                `conda update ____`
            * Update all packages
                `conda update --all`
            * Find a package
                `conda search ___`
            * Export list of packages in environment to file for easy loading dependencies by others (similar to `pip freeze > requirements.txt`)
                `conda ` 
        * Other
            * Help `conda install --help`
    * Installation of Conda
        * Anaconda 
            * Download https://www.continuum.io/downloads
            * Cheat Sheet of Installation https://docs.continuum.io/_downloads/Anaconda_CheatSheet.pdf
        * Miniconda https://conda.io/miniconda.html
            * https://github.com/conda/conda
            * Download v3.5
            * Run with `bash Miniconda3-latest-MacOSX-x86_64.sh`
            * Check installation location
                `which conda` => /Users/Ls/miniconda3/bin/conda
                `conda list`
                
                ```
                 # packages in environment at /Users/Ls/miniconda3:
                 #
                 cffi                      1.9.1                    py36_0  
                 conda                     4.3.11                   py36_0  
                 conda-env                 2.6.0                         0  
                 cryptography              1.7.1                    py36_0  
                 idna                      2.2                      py36_0  
                 openssl                   1.0.2k                        0  
                 pip                       9.0.1                    py36_1  
                 pyasn1                    0.1.9                    py36_0  
                 pycosat                   0.6.1                    py36_1  
                 pycparser                 2.17                     py36_0  
                 pyopenssl                 16.2.0                   py36_0  
                 python                    3.6.0                         0  
                 readline                  6.2                           2  
                 requests                  2.12.4                   py36_0  
                 ruamel_yaml               0.11.14                  py36_1  
                 setuptools                27.2.0                   py36_0  
                 six                       1.10.0                   py36_0  
                 sqlite                    3.13.0                        0  
                 tk                        8.5.18                        0  
                 wheel                     0.29.0                   py36_0  
                 xz                        5.2.2                         1  
                 yaml                      0.1.6                         0  
                 zlib                      1.2.8                         3
                ```
        * List envs

        `conda info --envs` (or `conda env list`)
        
        ```
         # conda environments:
         #
         root                  *  /Users/Ls/miniconda3
         ```
         
         * Clone the root env
         
         `conda create --name rootclone --clone root`
         
         * Create env with specific Python version 
         `conda create --name aind-3.6.0 python=3.6.0`
         
         * Checkout the aind env
         
         `source activate aind`
     
         * Save env (incl packages and Python version for sharing). 
          Also include a pip requirements.txt file using `pip freeze` for people not using conda
         
         `conda env export > environment.yaml`
         `pip freeze > requirements.txt`
         
         * Load env from YAML env file `conda env create -f environment.yaml`
           
    * Installation of Spyder IDE
        * https://github.com/spyder-ide/spyder
        
        * Create subenv with Spyder IDE, update to latest versions
            `source activate root`
            `(root) $ python --version` ==> 3.6.0
            `(root) $ conda upgrade conda`
            `(root) $ conda upgrade --all`
            `(root) $ conda create -n spyder python=3.6.0`
            `(root) $ source activate spyder`
        * Install Spyder IDE in subenv
            `(spyder) $ conda install qt pyqt`
            `(spyder) $ conda install spyder`
            `(spyder) $ conda upgrade --all`
        * Run Spyder IDE
            `(spyder) $ spyder`
            
    * Python 3 vs Python 3
        * Usage of `print` from Python 2 instead of Python 3's print function (surround with `print("a","b")` not `print "a" "b"`)
        * Use new print function in old Python 2 code by importing `from __future__ import print_function`

    * Env variables
        * https://conda.io/docs/using/envs.html
    * Pre-load with AI Nanodegree Python environment
        * Download aind-environment-unix.yml
        * Load `conda env create -f /Users/Ls/Downloads/aind-environment-unix.yml`
        * Switch to AIND env `source activate aind`
    * Install PyGame for visualisations of AI programs for portfolio sharing
        `brew install sdl sdl_image sdl_mixer sdl_ttf portmidi mercurial`
        `pip install pygame`
    * Get PyGame library directory
        ```
        >>> import site;print(site.getsitepackages())
        ['~/miniconda3/envs/aind/lib/python3.6/site-packages']
        ```
    * Within IntelliJ, go to Project Structure (CMD+;)> Platform Settings > SDKs, and Add
    `~/miniconda3/bin/python` as a Python 3.6.0 SDK home path, then add to this an additional Classpath
     of `~/miniconda3/envs/aind/lib/python3.6/site-packages`
    * Within IntelliJ, go to Project Structure > Platform Settings > Modules
    
* Project 1 - Suduko
    * About Sudoku http://www.conceptispuzzles.com/?uri=puzzle/sudoku/rules
        * Given: 9x9 grid partially completed
        * Objective: Fill grid with missing digits so each row, each col, and
        each of 9 principal 3x3 sub-squares contains all digits 1-9
        * Extras:
            * Strategies other than Naked Twins like:
            (Standard + Diagonal Sudoku)
    * Goal
        * Build an AI-agent that solves all Sudoku problems and 
        provides intro to techniques: Constraint Propagation, and Search
    * Note: **AI**
        * Composed of combining many simple ideas to solve complex problem 
    * Dfn: **Constraint Propagation**
        * e.g: Extract max info from applying simple Local Constraints (i.e. to each square) 
        to iteratively narrow search space of possible solutions
        * Risk: Never solve every puzzle (incl. hard ones)
        * Example: Elimination of possible values for each peer within each square
        here http://norvig.com/sudoku.html states that even using 
        **Naked Twins** strategy we never know if we can solve every puzzle (even hard ones)
    * Dfn: Search
        * e.g. Given two or more possibilities available, branch out and create whole
        tree of possibilities, then traverse tree and consider all until find solution
        * Risk: May take forever to run
        * Example: 
            * Option 1: **Brute Force** Approach: Single machine instruction http://norvig.com/sudoku.html
            (i.e. try all possibilities, takes a long time)
            * Option 2: **Constraint Propagation** (Constraint satisfaction problem): Multiple machine instructions each processing
            multiple possibilities (i.e. eliminate possibilities on each try, so not need try all possibilities)
                * https://en.wikipedia.org/wiki/Constraint_satisfaction
                * https://en.wikipedia.org/wiki/Search_algorithm
                * **Depth-First Search** Algorithm:
                    * Dfn: Depth First Search (DFS) algorithm traverses a graph in a depthward motion
                    and uses a stack to remember to get the next vertex to start a search, 
                    when a dead end occurs in any iteration
                    * Check not already found solution or contradiction
                    * Select unfilled square and try possible values until find successful value, 
                    and for each possible value check if with that possible value we can successfully
                    search for a solution.
                    * Note: This is a **recursive search** since we recursively consider all possibile
                    outcomes for a value before trying a different value
                    * Note: Create new copy of values for each recursive call to search so each branch
                    of the search tree is independent and does not confuse other branches
                    (hence may be more efficient to implement set of possible values for a Sudoku square as 
                    a string, rather than a Set or a List)
                * **Search Implementation**
                    * **Variable Ordering** - i.e. choice of which square to try first
                        * **Minimum Remaining Values Heuristic** - i.e. choose a square with min. qty of possible values
                            * i.e. if choose square with 7 possibilities we expect to guess wrong with probability
                            of 6/7, whereas if choose square with 2 possibilities we expect only 1/2 (50%) probability
                    * **Value Ordering** - i.e. choice of which digit to try for first Sudoku square
                    * **Randomize Ordering Heuristic** - Randomise the value ordering may avoid any deadly combinations of value choices
                    that may take 10,000 times longer to find a contradiction
                    * **Least-Constraining Value Heuristic** - Chooses the first value that imposes the least 
                    constraints on peers
    * Problem: 
        ```
        . . 3 |. 2 . |6 . .
        9 . . |3 . 5 |. . 1
        . . 1 |8 . 6 |4 . .
        ------+------+------
        . . 8 |1 . 2 |9 . .
        7 . . |. . . |. . 8
        . . 6 |7 . 8 |2 . .
        ------+------+------
        . . 2 |6 . 9 |5 . .
        8 . . |2 . 3 |. . 9
        . . 5 |. 1 . |3 . .
        ```
    * Solution: '483921657, 967345821, 251876493, 548132976, 729564138, 136798245, 372689514, 814253769, 695417382'
        ```
          1 2 3  4 5 6  7 8 9
        A 4 8 3 |9 2 1 |6 5 7
        B 9 6 7 |3 4 5 |8 2 1
        C 2 5 1 |8 7 6 |4 9 3
          ------+------+------
        D 5 4 8 |1 3 2 |9 7 6
        E 7 2 9 |5 6 4 |1 3 8
        F 1 3 6 |7 9 8 |2 4 5
          ------+------+------
        G 3 7 2 |6 8 9 |5 1 4
        H 8 1 4 |2 5 3 |7 6 9
        I 6 9 5 |4 1 7 |3 8 2
        ```
    * Steps:
        * If box has a value, then all boxes in same row, same column, or same 3x3 square cannot have same value
        * If only one allowed value for given box in row, column, or 3x3 square, then the box is assigned that value
        * Naming Conventions
            * Rows and Columns
                * Rows labelled A, B, C, D, E, F, G, H, I.
                * Columns labelled 1, 2, 3, 4, 5, 6, 7, 8, 9
            * 3x3 squares will not be labelled
            * Boxes, Units and Peers (name important elements created by rows and columns)
                    * Boxes - Individual squares at the intersection of rows and columns (i.e. 'A1', 'A2', ..., 'I9')
                    * Units - Complete rows, columns, and 3x3 squares. Each unit is a set of 9 boxes, there are 27 units total.
                    * Peers - All other boxes associated with a particular box (such as 'A1'), that belong to the same unit 
                    (i.e. belong to the same row, column, or 3x3 square)
                    (i.e.  Peers of 'A1': row: A2, A3, A4, A5, A6, A7, A8, A9 
                                          column: B1, C1, D1, E1, F1, G1, H1, I1 3x3 
                                          square: B2, B3, C2, C3 (since A1, A2, A3, B1, C1 are already counted).
                    * Note: Each box has 20 peers
        * Elimination Strategy:
            * Eliminate possible values for a box by analysing peers
            * If a box has a value assigned, then none of its peers may also have its value
            * Update grid with possible values for each box
            * Use to compute `grid_values()` so each box value represents all the available 
            values for that box. i.e. i.e. box 'B5' would have value '47' 
            (because 4 and 7 are its only possible values).
            Starting value returned for every empty box will be '123456789' instead of '.'
        * Only Choice Technique:
            * If one of the possible values in any one of the unsolved boxes of a
            unit/square that is not also one of the remaining values in the other
            unsolved boxes, then it is the Only Choice for that box
        * Search Strategy:
            * Example Usage:
                * Game Playing
                * Route Planning (to find solutions efficiently)
                * Alpha Go https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf
                    * Selection
                    * Expansion
                    * Evaluation
                    * Backup
                * **Depth First Search Algorithm** Steps:
                    * Start from root, traverse the tree always in the most-left-first
                    fashion, and when reach end leaf, move to next branch
                    * Step 1: Pick an unsolved box that has the fewest possible numbers
                    to try out i.e. 89 (less work), and create a
                    Tree of possibilities to try out
                    * Step 2:
                        * Step 2a: Try the first branch's possible value of 8, using
                        Constraint Propagation
                        * Step 2b: If not done after first branch's first level, then choose
                        from that unit/square another box with fewest possible numbers
                        (i.e. 159), and create 3x 2nd level branches to Try solving with
                        using 8 with each of its values (i.e. 1, 5, and 9) using
                        Constraint Propagation
                        * Step 2c: Repeat with more levels as required

                    * Step 3: Try for remaining branches
                    * Step 2: If Step 1-3 results in no solution, repeat for another one
                     of its possible values
                    * Note: 4x more work, but each step gets easier
        * Constraint Propagation:
            * Using local constraints in a space (i.e. Sudoku square constraints)
            to reduce search space. Each constraint that is enforced introduces
            new constraints for other parts of board that helps reduce remaining
            possibilities
                * Example Usage:
                    * Map Coloring Problem: Prevent two adjacent map segments from having same color
                    * Crypto-Arithmetic Puzzles: Where each unique letter represents a digit
                    in a calculation (i.e. TWO + TWO = FOUR), and no number starts with a 0.
                    Goal is find mapping from letters to digits to satisfy equations by
                    using constraints imposed by the equation to create an AI-agent to solve the
                    proble via Contraint Propagation
                    * Sudoku:
                        * Options:
                            * Constraints: Elimination
                                * Pick solved box, and apply the Eliminate function to
                                remove the value of the box from the possibilities of its peers
                            * Constraints: Only Choice
                                * Pick a Unit, if there is one value in the unsolved boxes
                                that is only allowed in one of the boxes, then assign it to
                                the box
                            * Constraints: Search
                                * Use Depth First Search algorithm to solve harder Sudoku problems
                                 using recursion and calling function that uses Constraint Propagation
                                 (i.e. Elimination and Only Choice techniques)
                            * Note: **Constraint Propagation Technique
                            (using Elim & Only Choice)** Applied
                                * Step 1: Pick a solved box and apply Eliminate function
                                * Step 2: With the more complete grid, pick a Unit and apply
                                Only Choice function
                                * Step 3: Repeat Step 1 for a different solved box
                                * Step 4: Repeat Step 2
                                * etc
                                * Solution ?? Or Stuck ?
                                * **Important Note:** May only handle EASY puzzle
        * Naked Twins Technique (extension) http://www.sudokudragon.com/tutorialnakedtwins.htm
            * Given a Sudoku puzzle partially completed with some boxes with possibilities for their
            values. If there are two boxes in the same row or column that both contain the same two values
            i.e. 23 and 23, then we know for sure that 2 and 3 can only occur in those boes in that
            unit (column 3), so:
                * Remove 2 and 3 from possible values in that column
        * Diagonal Sudoku (by modifying the algorithm)
    * Project 1:
        * Added Python Debugging functionality from main.py file (see my Gists on GitHub)
        * Added assertions
        * Get PyGame library directory
            ```
            >>> import site;print(site.getsitepackages())
            ['/Users/Ls/miniconda3/envs/aind/lib/python3.6/site-packages']
            ```
        * Code Review Comments:
            * Logging with default level ERROR could be added to debug the code.
            Logs can also help to understand the algorithms.
            See https://docs.python.org/3/howto/logging.html
            * Assert statements could be used https://wiki.python.org/moin/UsingAssertionsEffectively
        * Utility methods in separate file
    * MyPy - Static Type Checking
        * Install MyPy `python3 -m pip install mypy`.
        * Install Typing `python3 -m pip install typing`.
        * Import Typing `import typing; from typing import *`,
        * Apply MyPy static type checking to an existing function where expect warnings
            `def solve(grid: str) -> None:`
        * Run MyPy Linter with `mypy solution.py`
        * Apply MyPy with expected types `def solve(grid: str) -> typing.Dict:`

        * Installation http://mypy.readthedocs.io/en/latest/getting_started.html#getting-started
            `python3 -m pip install mypy`
            * Also installed `typing`, even though at this website it says it's only necessary
            when running old Python 2 http://mypy.readthedocs.io/en/latest/faq.html
                `python3 -m pip install typing`
                * And then added to top of file:
                    `import typing; from typing import *`
                * Implemented into function with:
                    `def solve(grid: str) -> typing.Dict:`
            * Run MyPy Linter
                `mypy solution.py`
        * Basic Summary http://mypy.readthedocs.io/en/latest/basics.html
        * Note:
            * Example built-in types: http://mypy.readthedocs.io/en/latest/builtin_types.html
        * Run MyPy Linter that performs type checking of program without running it and provides warnings
            `mypy program.py`
            ```
            PySudoku.py:1: error: Cannot find module named 'pygame'
            PySudoku.py:1: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
            PySudoku.py:3: error: Cannot find module named 'SudokuSquare'
            PySudoku.py:4: error: Cannot find module named 'GameResources'
            PySudoku.py:65: error: Name 'main' is not defined
            ```
        * Extend MyPy Linter to perform type checking of Libraries that have Stubs that
         are skeletons of public interface of library classes, variables, functions and their types
         but with Dummy function bodies (i.e.
         those incorporated in the Typeshed project from Python Built-ins and Standard Library)
            * Type inference of uses Stubs for definitions
                ```
                # Sample code in .py file
                x = chr(4)

                # Sample MyPy Library Stub in .pyi file (ellipsis used for function body)
                def chr(code: int) -> str: ...
                ```
            * Create Custom Stubs https://github.com/python/mypy/wiki/Creating-Stubs-For-Python-Modules
                * Write Library Stub in .pyi file within either same directory as the Library Module OR
                in specific Stub directory (i.e. myproject/stubs) and set environment variable
                pointing to `export MYPYPATH=~/work/myproject/stubs`
                * Use subdirectory with `__init__.pyi` for packages
                * In directories with both `.pyi` and `.py` the `.pyi` file takes precedence
        * Contribute Custom Library Stubs created into the Typeshed Repo
        * Static Type Checking (instead of Dynamic Type Checking)
            * Type Annotations added to functions (type checker reports type errors within function)
            * Apply return type as None by default so statically typed context results in type check error
                ```
                def greeting(name: str, prefix: str = 'Mr.') -> None:
                     return 'Hello, {} {}'.format(name, prefix)
                ```
            * Use `typing` module to use type definitions in statically typed code
                ```
                from typing import Iterable

                def greet_all(names: Iterable[str]) -> None:
                    for name in names:
                        print('Hello, {}'.format(name))
                ```
        * Previously Dynamic Type Checking
            * No type checking annotation in function signatures
    * Lesson 4: Intro to AI
        * **Optimisation** of Navigation and Route Finding Domain
            * Computationally hard problems
                * Find shortest path on map from A to B
                    * Apply graph of city nodes
                    * Connect city nodes by road edges
                * Option 1: **Breadth-First Search**
                    * Inefficencies
                        * Considers all possible paths out of city until
                    reaches destination via one of them
                        * Only considers major roadways
                    * Issues
                        * Intractable space of possible paths to search
                        if consider smaller streets/alleys
                * Option 2: Heuristic to Manually Solve (i.e. AI for smart idea, a rule,
                function, or constraint that informs an otherwise
                Brute-force Algorithm to act more optimally)
                    * Consider major roads
                    * Defer considering major roads going too far
                    * Prioritise paths that take closer to destination
                * Option 3: **A\* Search Algorithm**
                    * Draw straight line path between source and destination
                    * Priorities how our algorithm considers and evaluates
                    different possibilities by try testing
                    (using Direct Distance Heuristic)
                    all possible next steps from current position
                    so new direct distance changes (prevent unnecessary
                    searching and converges on optimal direction quickly).
                    Choose Most Promising Choice with smallest
                    direct distance as next step (but may not turn out to be
                    Optimal). Store each other path for later consideration.
        * **Intelligent Agent**
            * **Dfn**: Actions taken to Maximise its expected Utility given desired Goal
            * **Comparison of Agents**
                * **Rational Behaviour** extent - requires Optimal Behaviour
                 (regardless of what Cognitive Mechanism used),
                 however, the Optimal Solution is hard to achieve (i.e. Sudoku problem, etc),
                 but AI-agents are not always expected to perform Optimally
                * **Constraints** faced by the AI-agent must also be considered
                    i.e.
                    * Partially Observable env
                    * Limited computational resources (speed, memory)
                    * Rules of task such as require respond by deadline
                * **Bounded Optimality**
                    * Quantifying Intelligence feasibly and practically
                    * Level of Performance / Bound for AI-agent to meet
                    (i.e. Chess AI-agent to win 60% of time against human chess masters,
                    or Route Finding Algorithm that always find route no more than
                    2km longer than Optimal route)
            * i.e. Anticipate and React to changes in environment (i.e. other drivers)

        * **Game AI-Agent** (Tic Tac Toe)
            * Goal - Design AI-agent to play Game (Tic Tac Toe) using
            Search Strategy (similar to route-finding problem)
            * Step 1
                * Determine Nodes and Edges in the Graph we search
                    * Option A -
                        * Nodes - Each cell
                        * Edges - Connect two if adjacent
                        * INSUFFICIENT - Does not capture enough info on what to do next
                    * Option B -
                        * Node & Edges - Current Player position (row/col Tuple)
                        {0, 1, 2}
                        Note: Two Nodes connectable if row/col differ by 1
                        (i.e. (0, 1) connectable to (1, 0) but not (2, 2)
                        * INSUFFICIENT
                    * Option C -
                        * Opponent Tracking - Track of opponents position too
                        * Node - Tuple (i.e. <(0, 1), (2, 0)>
                        * Edges - Connect if both Player positions differ
                        by max 1
                        * INSUFFICIENT - Since need know which cells already
                        filled, as cannot move into them
                    * CORRECT - Option D -
                        * Node - **Whole Board is Node**, with one Node for every
                         possible arrangement of X's and O's
                        * Edges - Connect two Nodes if there is a valid move
                        that changes the board from one node to another
                            * The edges embody the **Rules** of the game
                                * i.e. only possible to go to finite qty of
                                next states from current state
                                (limits qty of moves need to consider)
                        * SUFFICIENT - Usable for Tic Tac Toe!!! Since will know
                        position of Computer Player and Opponent Player so
                        know what to do next (by Excludes any extraneous details
                        we don't need to solve it)
                        * Note:
                            * 3x3 Board -
                                * First Computer Move - 9 possibilities
                                * First Opponent Move - 8 possibilities
                                * etc
                        * Note: Search Indicators
                            * **Pruning the Search Tree**
                                * Ignorable / Non-Winnable Moves (some moves are wasteful)
                                    * Evaluated Condition - i.e. When enemy has X on same row and column and proposed placement
                            * **Adversarial Search**
                                * **Minimax Algorithm** (maximise chance of win on our turn, whilst enemy trying to
                                minimise our chance of win on their turn)
                                Note: **AI-agent Dfn - Anticipates and plans around expected changes in its environment,
                                including those introduced by other agents**
                                    * Anticipate Enemy Movies (intuition of recognising that enemy is Human also trying to Win)
                                        * Evaluate Condition - i.e. When enemy can make sequence of moves that win after our move
                                            * **Rule Out** certain moves as being BAD removes
                                            potential successors from its consideration
        * **Monty Hall Problem**
            * Given 3x doors, randomly assigned behind each is either car or goat
                * Strategy:
                    * Stay   - Wins 33.33% of time
                    * Switch - Wins 66.67% of time

                * Strategy:
                 1) C G G - better to STAY
                    x 0

                 2) C G G - better to STAY
                    x   0

                 3) C G G - better to SWITCH
                      x 0

                    C G G - never, so counts as 3) probability
                    0 x

                 4) C G G - better to SWITCH
                      0 x

                    C G G - never, so counts as 4) probability
                    0   x
            * **Probability Theory** - captures uncertainty in
            real-world to make sensible decisions when unsure
                * **Prior Probability** - best guess given no other evidence
                    ```
                    P(CarA) + P(CarB) + P(CarC) == 1
                    P(CarA) == 1/3, P(CarB) == 1/3, P(CarC) == 1/3 (aka **Prior Probability**)
                    ```

                    * Equal to 1 since probability of at least one
                    is car is 100% (sum of probabilities equals 1)
                    * So each door has 1/3 probability of car behind it
                * **Move 1** -
                    * Player 1 Select door A
                    * Monty Open door B
                        * OpenB (Bbservation)
                        * **Posterior Probability** - belief after making an Observation
                        ```
                        P(CarB | OpenB) == 0
                        ```
                        * Note: 2x doors still undisclosed, probability of car behind either
                        is NOT 1/2, since Monty (enemy) knowingly opened door with
                        Goat behind it (never reveal the car on this move)
                        ```
                        NOT THIS - P(CarA) == 1/2, P(CarC) == 1/2
                        ```

                        * We are actually interested in Posterior Probability of finding
                         car behind Door C, given that Monty opened Door B, and the implicit
                         Rule that Monty never reveals the car, so
                         express the **Posterior Probability** in terms of other quantities
                         that can compute using **Bayes' Theorem**
                            ```
                            P(CarC | OpenB) ==

                                == (P(OpenB | CarC) * P(CarC)) / P(OpenB)
                                == (Likelihood * Prior) / Marginal Probability

                                Likelihoood:
                                    where P(OpenB | CarC) == 1
                                    since if CarC true, Monty's only option is OpenB,
                                    since OpenA already picked by us (not option to Monty)

                                Prior:
                                    where P(CarC) == 1/3,
                                    which previously computed as 1/3

                                Marginal Probability:
                                    P(OpenB) == Possibility 1 + Possibility 2 + Possibility 3
                                                    where Possibility 1:
                                                        Car behind A with 1/3 possibility, and in this case Monty either:
                                                        OpenB or OpenC, both with 1/2 possibility,
                                                        so Probability of OpenB **given** CarA is 1/3 (i.e. P(OpenB | CarA))

                                                    where Possibility 2:
                                                        Car behind B has 1/3 possibility, but in this case
                                                        Monty would not reveal it, so Probability of OpenB
                                                        given CarB is 0
                                             == P(CarA) * P(OpenB | CarA) +
                                                P(CarB) * P(OpenB | CarB) +
                                                P(CarC) * P(OpenB | CarC)
                                             == 1/3     * 1/2             +
                                                1/3     * 0               +
                                                1/3     * 1
                                             == 1/6 + 1/3
                                             == 1/2

                                 so, updated Bayes' Theorem
                                 == (Likelihood * Prior) / Marginal Probability
                                 == (1          * 1/3  ) / 1/2
                                 == 2/3
                                 (so probability that the car is behind the other closed door has
                                  increased to 2/3)
                            ```
                * Note: **Empirical Evaluation** (by characterisation of given situation
                coupled with a formal method helps make decisions in face of **Uncertainty**)
                shows that consistent switch strategy wins 2/3 of time

        * **Intelligence Dfn**:
            * Ability to produce Reasonable behaviour while dealing with different
            sources of complexity
                * Intelligent Objects: Thermos, Plant, Siri, Rock, Arpan
                * E.g: If a person you know was not human but acted same,
                 you probably wouldn't tell the difference

            * Note:
                * **Intelligence** often used to label this we cannot explain,
                * **Artificial General Intelligence Dfn** (sub-field of AI) deals with goal of:
                    * Ability to replicate complex nature of human thinking that accomplishes
                     a variety of intellectual tasks like humans do
                * **Algorithms** or **Formulas** used to label things we CAN explain
                * Philosophically this implies that:
                    * Anything we design can never be intelligent, as we would know how it works
                    * Humans assume they are intelligent now, as we do not fully understand how brains work,
                    but when we do, will we not consider ourselves intelligent anymore?
                * **Intelligence** - **must not be contingent on how we Perceive something**
                * **Intelligence** **must be a Property that emerges from the system itself**
                * **Intelligence** - **should be defined as the ability to do something
                                     with a decent rate of success within the Context of a task
                                     so then can say you are Intelligent at solving Sudoku puzzles**

                 (quote by Luke Schoen i.e. Our judgement of the "truth" of something, similar to our
                  judgement of the "intelligence" of something, should not be contingent on how we "perceive" that
                  something. Instead our judgement should be based on assessing "properties" that
                  emerge from the "source" of that something itself, and should be defined based
                  on that somethings' "success rate" at being able to be "truthful" within a defined
                  "context" such as a task)
                * Humans are **Intelligent** at doing Multiple tasks (many things)

        * **Agent Design (i.e. AI-agent)** (i.e. aka Intelligent Systems)
            * AI-agent Dfn:
                * Cartesion View:
                    * Software only is the AI-agent, whereas the Hardware (i.e. sensors) is considered
                * High-level View:
                    * Entire robot is the AI-agent, all components directly reliably accessible/controllable
            part of the Environment
            * Example:
                * Automatic Vacuum - i.e. specification

                    * **Environment Understanding (Domain of Task / Problem)**
                        * room operating in, floor, walls, objects to avoid
                        bumping into, except objects not of concern
                    * **State** stored is only items necessary to complete task
                        * current position
                        * orientation while making actions
                        * places already been before
                        * obstacle location map (but they may move over time)

                    * **Goal State** stored - result the AI-agent trying to achieve
                        (i.e. final location(s) acceptable)

        * Agent Interaction with Environment
            * Input
                * **Perception** - Sensing the Properties of Env
                * **Effectors**
            * Internal
                * **Cognition** - Based on Perceived Inputs, the process of:
                    * Reasoning
                    * Decision Making
                    * Action
                * Note:
                    * **Reactive / Behaviour-based Agents**
                        * Simple pre-programmed behaviours and directly associate
                        Actions with Perception (bypassing process)
                        (i.e. automated rubbish bin that senses something infront of it)
                * **Classification of Agents**
                    * Classification Measures: - based on
                        * Processing they do, the kind of
                        * Environment Properties
                        **Environment States** components they must capture
                            * **Fully Observable** (i.e. Tic Tac Toe where whole board viewable)
                            * **Partially Observable** (i.e. Battleship game where opponent
                                positions hidden)
                            * **Deterministic** (i.e. where **Certain** of Action outcomes)
                            * **Stochastic** (i.e. where **Uncertainty** in Action outcomes)
                            * **Discrete** (i.e. finite qty of States the env may be in)
                            * **Continuous** (i.e. infinite qty of States such as due to
                                            Properties that need to be stored as real numbers)

                            * **Benign** (i.e. where AI-agent is only one taking Actions
                                            that intentionally affect its Goal, i.e other Random
                                            events may be occurring)
                            * **Adversarial** (i.e. where one or multiple AI-agents that can take
                                            Action to defeat its Goal, i.e. competitive games)

                        * e.g.
                            * Playing Poker - Partially Obs, Stoch., Adversarial
                            * Recognition of Hand-written Text - Stochastic, Continuous (since
                                source is physical object with arbitrary and unpredictable motions)
                            * Driving on Road - All except Adversarial
                            * Playing Chess - Advers.

                    * **Layering** simple **Reactive** control
                    in a Hierarchy may achieve complex Behaviour
                    * **Deliberate / Non-Trivial Processing** by agents such as:
                        * **Knowledge-based Agents**
                        * **Game Playing Agents**
                        * **Path Planning Agents**
                        * **Learning Agents**

            * Output
                * **Actions** - Changing the State of Env

    * Lesson 5: Intro to Game Programming
        * Course Outline
            * **Search and Logic and Planning** - Peter Norvig
            * **Probability and Bayesian Networks (BN)** - Sebastian Thrun
            * Other - Thad Starner

        * Goal of Lesson
            * Design a Game AI-agent program smarter than ourselves when playing a
            the limited context of a single real game

        * Main Topics
            * **Adversarial Search** - find optimal moves
            * **Minimax Algorithm** - for **Deterministic Games** determines
                                  best move for any turn in a game
            * **Expectimax Algorithm** - for **Non-Deterministic Games** (Chance games)
                                that considers all possible outcomes and chooses the
                                one with maximum expected return
                                (assuming opponent is making best moves available)
                * **Expectimax Game Tree**
                    * Maximising Nodes - indicated by upward facing triangles
                    * Minimising Nodes - indicated by downward facing triangles
                    * Probabilistic Nodes - indicated by circles with the Chance of
                                        each outcome labelled on branches below it
                    * Evaluation of Tree Approach - evaluate tree from left to right
                    * Note: Game Board Nodes - values may range from -10 to +10
            * **Alpha-Beta Pruning** - helps optimise the Minimax / Expectimax Algorithm to
                                       make AI-agent play faster
                    * Performance Improvements:
                        * Apply to expected max game trees that have finite limits
                        on values the evaluation function returns
                    * Usage: Use the Alpha-Beta Algorithm to mark trees branches that
                      do not need to be visited, to calculate the value of the optimum
                      choice
            * **Evaluation Function** - creation of them for games
            * **Isolation Game Player** - apply knowledge to the Isolation Game (a complex game
            with simple rules)
                * Objective: To not become isolated an unable to move on your turn
                (i.e. be the last player to move)
                * Setup: 5x5 board, 2x players with X and O pieces
                * Movement Rules: Move permitted to any square up/down or diagonal
                from current position, but not through:
                    * opponents position
                    * previously occupied position (i.e. landed upon)
                    * outside game board position
                * https://www.youtube.com/watch?v=n_ExdXeLNTk
                * Note: Hard to estimate chances of winning at start of game,
                 but become more certain as game progresses
                * **Minimax Algorithm** Usage:
                        * Automatic first choice consults **Openning Book - Table of Best First Moves
                        (used for End Games)** for this board config
                        * Discover best moves, i.e.
                            * **Move to positions that are always at least above, or in the
                                position immediately above the opposition position**
                            * **Move to positions with available escape options
                                (unless can block and win on that specific move);
                                and closest to other player position;
                                and avoid some first moves entirely (i.e. top middle or bottom middle);
                                higher odds of winning when make first move on 3x2 (w/h) board
                                with bottom right position blocked off**
                            * Mark (with **Downward Arrow** above) Scores at **Terminal** (Leaf) Nodes
                                * +1 for Win
                                * -1 for Lose
                            * Assumption 0: Maximization of score is being considered from the **Perspective**
                              of the [Computer] (otherwise we'd reverse how we apply Minmax). The [Computer]
                              can only affect the game on its turn.
                              Top of Minimax Algorithm Tree is always a Maximize (**Upward Arrow** Below)
                            * Assumption 1:
                                * Player X [Computer] always tries to maximise its score
                            * Assumption 2:
                                * Player X [Computer] is smart and latest positions are due to them
                                always plays to win trying to minimise Player O's score, so they make
                                bad moves and lose soon)
                            * Mark Assumption 1 (with **Upward Arrow** Below, i.e. [Computer]'s Turns) on Tree,
                              Turns when Player X [Computer] is trying to Maximise the score
                            * Mark Assumption 2 (with **Downward Arrow** Below, i.e. [Human]'s Turns) on Tree,
                              Turns when Player X [Computer] is trying to Minimise the score
                              (i.e. Player O Turns where Player X [Computer] reliant on their Bad Move)


                    * Move to positions that partition the board (fill positions on one side
                    of board to reduce positions to move to to force early end to the game)
                    * Move to positions that try to Trap the opposition
                * Example:
                    * Build a Game Tree (showing all possible movies) based on 2x3 game board
                    * Game Tree used to select moves with best change of winning
                    * Rules:
                        * Unavailable Moves: Any filled spot on game board
                    * Human is X, Computer is O.
                    * Mark Leaf (**Terminal Nodes**) branches where WIN with +1, and LOSE with -1.
                    * Level 0 (Beginning Game Level) - bottom left is unavailable immediately.
                        * Draw Level 0 of **Game Tree** as top of tree

                    * Level 1 [Computer] - 5x possible moves.
                        * Draw Level 1 of **Game Tree** as 5x branches possibilities below Level 0
                    * Level 2 [Human] - 4x possible moves (reduces)
                        * Draw Level 2 of **Game Tree** as 4x branches below EACH Level 1 branch
                    * Level 3 [Computer] - 3x OR 2x OR 1x possible moves (exponential growth)
                                           (some moves BLOCKED by X, or BLINDSPOT)
                    * Level 4 [Human] - 2x OR 1x possible moves (becomes denses)
                    * Level 5 [Computer] - 1x OR 0x possible moves (multiple LOSE possibility)
                    * **Note** Warn [Computer] not to make Level 3 moves that allow
                    Level 4 branch to be one that gives [Human]'s a possible that results in
                    on 0x possible moves for [Computer] in Level 5
                    * Level 6 [Human] - 0x possible moves (i.e. Computer Win if get to this level)

                    * **Minimax Algorithm** Dfn -
                        **Back Propagate possible future wins/losses up game tree** to [Computer] so
                    best possible first move is made
                        * Start Bottom Left Leaf **Terminal Node**
                        * Go Upward and if get:
                            * **Downward Arrow** choose the Min value (from -1 or +1) appearing in Child Nodes
                                (Turn where Player X [Computer] is trying to Minimise their opponents score)
                                * Note that **since [Computer] plays to win, it never chooses some branches
                                    allowing [Human] to win**, we want to
                                    **Mark these branches as -1 , as we want to Avoid future opportunities
                                    that MAY result in our loss, and;**

                            * **Upward Arrow** nodes on way up, pick the Max Value among its Child Nodes
                        * Note that if [Human] player makes a wiser choice at a higher tree level
                        it can avoid situation of [Computer] being able to play to win


            * **Multi-Player, Probabilistic Games**

        * Problem Solving and Game Playing
            * Strategy Games - i.e. checkers, isolation, othello, chess
            * Algorithms
                * **Reusable code, except modifying the code that
                generates all the next possible moves and the UI**,
                to create Computer Player for simple **Deterministic**
                games (where outcome of each move is known) such as
                Tic Tac Toe, or as complex as Chess
                * **Chance** games (i.e. backgammon)


        * Max Qty of Nodes Visited
            * Given
                * Isolation Game board: 5x5
                * Time to process all Upper Limit of Nodes:
                    ```
                    # Move 1 [Computer] - 25 possible places
                    # Move 2 [Human]    - 24 possible places
                    #                     23 ...

                    # i.e. 25 x 24 x 23 x 22 ... x 1
                           = 25!
                           = 10 ^ 25

                    # assume multi-core gigahertz processor able to do
                    # 10 ^ 9 operations/s it will take 10 ^ 16 seconds
                    # to search the entire game,
                    # where 10 ^ 16 sec
                      given 3600 sec/hr
                      given 24 hr/day
                      given 365 day/yr
                      = 317,097,920 years
                    ```
                * Time to process only up to Second Move:
                    ```
                    # 25 x 24 = 600
                    ```
                * Subsequent Moves from Third Move:
                    * Each subsequent move moves like a queen and less moves
                    * **Center** Position on board with Max Options to move on Third Move
                * **Branching Factor**
                    * Center has 16 possible positions
                    * Other Positions have <= 13 possible positions
                    * Max moves (depth of tree) in a game is 25
                    * Max possibilities from First and Second moves: 25 x 24 = 600
                    * 23 remaining moves after First and Second moves:
                        * <= 13 possible moves available (except center position)
                    * End Nodes Worst Case in game tree:
                        * 25 * 24 * 12 ^ 23 =  >10 ^ 27 estimate
                    ...
                    * Branching Factor of 12! factorial is far too much to
                     assume as being necessary for the last moves where not many
                     possibilities remain
                        * Fourth Last Move possibilities = <=3
                        * Third Last Move possibilities = <=2
                        * Second Last Move possibilities = 1
                        * Last Move possibilities = 0
                    * Instead assume this approximate is sufficient
                        ```
                        12 ^ 12 ~= 10 ^ 13
                        12 * 11 * ... * 3 * 2 * 1 = 5 * 10 ^ 8

                        25 * 24 * (12 ^ 13) * (5 * 10 ^ 8) ~= 3 * 10 ^ 23
                        (much better/faster than 10 ^ 27 since most branches will have less
                         than the max branching factor)
                        ```
                    * **Qty of Nodes in Game Tree that Minimax Algorithm must visit
                      to find Optimal solution is**:
                        * **b ^ d**
                            * Given grid: 5x5
                            * `b` (avg branch factor)
                            * `d` (depth of game tree)
                    * **Calculate Average Branching Factor**
                        * Option 1: **Brute Force**
                            * Try simple test first and add intelligence later
                            * Create game player than moves randomly and calculate
                              the avg branching factor
                              (use statics on each move: branches remaining, total games,
                               total plays, total branches, avg branching)
                              and we find the
                                * **Average Branching Factor**: 8
                                * **Estimated Max Nodes visited**: 8 ^ 25 ~= 10 ^ 22 (i.e. 1.2 million years for answer)
                        * Option 2: **Depth Limited Search** (Clever alternative to long end game search)
                            * Assume:
                                * Search Speed: 10^9 nodes * 2 sec  =  2 * 10^9 nodes
                                * Solve:    8^x              <  2 * 10^9
                                            log base 8  8^x  <  log base 8  2*10^9

                                    ```
                                    Math Formula:
                                    log base a  x  =  log base b  x  /  log base b  a
                                    ```

                                * So...:   x  <  log base 10  2 * 10^9 / log base 10  8
                                           x  <  10.3

                                    * Assuming **Branching Factor of 8** is good, to be on the safe side
                                      we should only go to **Max Depth of 9**
                                      (only go as deep as think need to meet deadline)

                                    * At **Depth of 9** we want an **Evaluation Function
                                    of a Node** to evaluate goodness of node at depth of 9
                                    based on how much we expect it to lead to Win for
                                    [Computer] player

                                        * Note: Only way for [Computer] player to Win is for it to have
                                        moves left at end of game, so maybe [Computer] **shouldn't
                                        maximize the number of moves it has early on**!

                                        * **Evaluation Function (aka "Number of #my_moves for convenience for Player 0")**
                                            * **Note** On each game tree branch
                                                * Min Branch (third last) - Mark min value of all below Max Branches
                                                * Max Branch (second last) - Mark max value of leaves below it
                                                * Leafs - Mark the maximum about of moves available to [Computer]
                                            * Arguments: Each game board generated level 9 of Minimax game tree
                                            * Returns: Number to compare that level 9 node with all other
                                            nodes at level 9. A higher number is returned is representative of how
                                            good the board is for the [Computer] player
                                            * Task: Counting number of moves the [Computer] has available at
                                            a given node, allows [Computer] to select branches from Minimax tree
                                            that lead to spaces where [Computer] has the most options
                                            * Also, use the **Evaluation Function** to test our **assumption**
                                            that if [Computer] makes a move to any middle position they will always lose.
                                            Try ONLY applying **Evaluation Function** down to Level 2 of game tree,
                                            to see that completely different nodes get higher scores, (the ones that
                                            would guarantee a loss!! Maybe they vary widely because critical decision being
                                            made at that level.
                                                * Demonstrates better to search to at least level 3
                                                * Check which branch the **Minimax Algorithm** recommends at
                                                each level of the search
                                                    * Use #my_moves Evaluation Function on Isolation Game with
                                                    Max score 5, Min score 0. If find branch where
                                                    [Computer] loses, give it score -1, or if find branch
                                                    where [Computer] wins, give it score 100..

                                                    * **Quiesence Search** is the state we reach if we continue to Level 3,
                                                    where the recommended branches no longer
                                                    change much so know we have gone far enough... and if continue
                                                    to Level 5, we just learn what we already know and values
                                                    become -1's and +1's
                                                        * Use this approach of determining deepest level to go to
                                                    if get consistent results
                                                        * Use this approach at Start and End of game when gives better results



                                                * **Depth-First Iterative Deepening (DFID)**
                                                    * References:
                                                        * AI Textbook: 3.4.5 of Russel, Norvig
                                                        * UBC Slides: https://www.cs.ubc.ca/~hutter/teaching/cpsc322/2-Search6-final.pdf
                                                        * Video showing how DFID vs DFS http://movingai.com/dfid.html

                                                    * Note: End Game is best critical time to apply DFID to see what will happen
                                                    (i.e. in Isolation game)
                                                    * Note: Using DFID means that our [Computer] player will always have an ANSWER READY
                                                    incase it runs out of time (whe limited time PER MOVE), and using it we can search as far as possible within its
                                                    time constraints. In other games where limited time PER GAME (i.e. speed chess)
                                                    so we would want [Computer] to search to different depths depending on point in the game
                                                    * **Strategy developed on how deep to search at different points in the game**
                                                        * **Strategy 1:**
                                                            * Beginning of game: **Standard Initial Moves**
                                                            * Middle of game: **Deeper Search (more time allocated) for Moves**
                                                            * End of game: **Less Time searching (as far as possible in remaining time) for Moves**
                                                            (relying on reduction and branching factor)
                                                        * **Strategy 2:**
                                                            * Conservative amount of time dedicated per Move
                                                            * Use DFID and Quiescent Search to determine few moves want to spend extra time on
                                                        * RISKS:
                                                            **Horizon Effect**
                                                                * Highlighting to [Computer] player critical
                                                                situations when game will be won/lost on next move
                                                                (but where [Computer] unable to search far enough
                                                                into future to discover problem exists)

                                                                * i.e. If a player is blocked on a side of
                                                                a Partition where they have less moves than if they
                                                                chose to move to the other side of the Partition
                                                                (in the board where Partition is created by previously
                                                                occupied positions)

                                                                * **Potential Solution** Add a process in your existing #my_move
                                                                **Simple Evaluation Function** to make it a
                                                                **Complex Evaluation Function** by additionally checking if a
                                                                **Partition** is being formed by the next move, and if so, count
                                                                the number of moves left to each player
                                                                (BUT this causes our Evaluation Function to take exponentially longer)

                                                                * **Solution**
                                                                    * **Strategy** Depending on game time available, carefully think
                                                                    how efficiently Evaluation Function may be implemented depending on
                                                                    strategy chosen, and whether it captures desired behaviour or not,
                                                                    either use. But BEFORE the **Evaluation Function**
                                                                    use **Alpha-Beta Pruning** (to improve efficiency of game tree search):

                                                                        * **Alpha-Beta Pruning Algorithm**
                                                                            * Dfn: Pruning technique to allow ignore whole sections
                                                                            of game tree but with same answer as with **Minimax Algorithm**
                                                                            so is MORE EFFICIENT, saving a lot of time.
                                                                            Where
                                                                            * **Minimax Algorithm** runs in a timeframe of `b ^ d`
                                                                            * **Minimax with Alpha-Beta Pruning (first)** runs in a timeframe of `b ^ d/2`
                                                                            (if nodes ordered optimally with best moves first), and down to timeframe of
                                                                            `b ^ d*3/4` (with random move ordering)
                                                                                * Firstly, When performing the **Minimax Algorithm** from left to right,
                                                                                after propogating the highest value up to the far left most bottom
                                                                                Max Node (Level -2) from that branch's two nodes (Level -1, aka leaf),
                                                                                (i.e. a value of 2) we know that the upward Min Node's (Level -3) subtree
                                                                                value will be <= 2... (since Opponent X will choose branch that minimises
                                                                                the value), so for each remaining Level -2 nodes, as soon as we find
                                                                                 they have a leave Level -1 node of value 2, we can ignore the rest of
                                                                                 its leaves and move on to next Level -2 node (i.e. if second
                                                                                  Level -2 Max Node has 3x leaf nodes, and we find first one is 2,
                                                                                  we can ignore the other two as they will never be selected), saving time!!
                                                                                  And based on this we know that at the highest Top node Level -4,
                                                                                  we will get a value of >= 2
                                                                                * Then, assuming Level -4 is the Top of the game tree.. when we
                                                                                 check the second from the left Level -3 subtree's ([Computer] turn)
                                                                                 Level -1's leaf nodes,
                                                                                 as soon as we find a value of 2 we know that is a Winning leaf, with its
                                                                                 upward Level -3 subtrees Min value being <= 2, so we can ignore the rest of
                                                                                 the branches below that subtree
                                                                                * Then, for third from the left Level -3 subtree's Level -1's leaf nodes,
                                                                                 as soon as we find a leaf with value of 2, we can ignore the remaining Level -2's
                                                                                 and associated leafs in that subtree, since we have already found a Max (Winning)
                                                                                 move in that subtree
                                                                                * Note: The above assumes our goal is to play the game, and that
                                                                                we choose from left to right using Minimax Algorithm, but not keep a list of all
                                                                                the equally good moves on a given level

                                                                                * **Reordering leaf nodes by only swapping siblings of a given parent**
                                                                                to increase amount pruned
                                                                                    * i.e. Since evaluate left to right, in right
                                                                                    subtree swap the Level -2 Max nodes around
                                                                                    so smallest is on left instead of on right, as Level -3 is Min, and may
                                                                                    only need to evaluate the left if we find Level -3 Min is less than
                                                                                    first subtree


                                                                        * **"Simple" Evaluation Function** and DEEP SEARCH, OR
                                                                        * **"Complex" Evaluation Function** and SHALLOW SEARCH
                                                                        to catch dangerous situations like the **Horizon Effect**, such as
                                                                        extensions of the **#my_move** **Simple Evaluation Function**
                                                                        that are correlated with our chances of winning including
                                                                        (try lots of Variants of Complex Evaluation Functions to see
                                                                        which ones are the best):
                                                                            * (**#my_moves** - **#opponent_moves**)
                                                                                * Note: Useful for Simple Isolation games
                                                                                * Favours moves where [Computer] has most options
                                                                                * Penalises moves where opponent has most options
                                                                                * Note: Possible to **weight the formula components** for
                                                                                more or less aggressive game play.
                                                                                    * i.e. to cause [Computer] to chase after Opponent, and
                                                                                    to make it so the **Winning Move has the highest Evaluation
                                                                                    Function result**
                                                                                        * (**#my_moves** - 2 * **#opponent_moves**)


                                                    * Init Goal: Want [Computer] to respond within < 2 sec per move
                                                    * Previously used Max Depth Calc: Calculated Max Depth we thought could search to
                                                    within that timeframe
                                                    * Simpler Iterative Deepening Approach:
                                                        * Search to Depth Level 1, get answer for best move,
                                                        Store answer to use incase run out of time
                                                        (L1 has 1 tree node, L2 has 3 tree nodes,
                                                        L1 has 1 iterative deepening nodes total,
                                                        L2 has 4 iterative deepending nodes total)
                                                        * Repeat process but search to Depth Level 2
                                                        * Repeat process until run out of time (returning best move
                                                        from level we get up to)
                                                    * Note: **number of Tree Nodes for each level** is the total number of
                                                    nodes visited when exploring the tree till that depth (not just
                                                    the nodes on that level)
                                                    * Note: **number of Iterative Deepening Nodes are simply the cumulative
                                                    sum at each level** (always less than double the number of tree nodes)
                                                    * Note:
                                                        ```
                                                            b = 2                    (Branching Factor of 2 given)
                                                            n = 2^(d+1) - 1          (Tree Nodes total)

                                                            b = 3                    (Branching Factor of 3 given)
                                                            n = (3^(d+1) - 1) / 2    (Tree Nodes total)

                                                            b = k                       (Branching Factor of k given)
                                                            n = (k^(d+1) - 1) / (k - 1) (Tree Nodes total)
                                                        ```
                                                    * Note: Iterative Deepening of researching the tree
                                                    does not waste too much time as
                                                    amount of time taken is dominated by last level searched
                                                    and is a small multiplier compared to
                                                    the DFS approach of checking every node from bottom leaf left to right
                                                    (exponential)
                                                    * Note: With Branching Factor of 2, DFID expands less than 2x
                                                    the qty of nodes a depth limited search would have done at the same level
                                                    * Note: With Branching Factor > 2 (i.e. most games) then the redundancy
                                                    caused by iterative deepening is even less

        * AI Definitions
            * AI NP (Hard) Problem Types
                * Non-Exponential
                * Exponential in Time OR
                * Exponential in Space OR
                * Exponential in Both Time AND Space
            * i.e. "AI is the studying of finding clever hacks to exponential problems"
                * When problem finally solved or computer finally fast enough to solve it,
                the world no longer thinks of the problem as belonging to AI
            * i.e. "AI consists of all the NP hard problems that have not yet been solved"
            * i.e. "AI involves working on everyday problems that improve people's lives"
            * AI Systems
                * System that helps consumers choose plane flights
                * System that determines when to deploy airbag in a car

        * Lesson 6.16:
            * Solving 5x5 Isolation Game
                * Searching to endgame in reasonable timeframe:
                    * **Minimax Algorithm with Alpha-Beta Pruning**
                      (reduces search space size of possible game states from b^d to b^(d/2)
                       i.e. from approx 8^25 to 8^12)
                    * **Symmetry Analysis** of board state that is defined as series of ordered moves
                        *
                            http://stackoverflow.com/questions/9082829/creating-2d-coordinates-map-in-python
                            http://stackoverflow.com/questions/32334322/find-adjacent-elements-in-a-2d-numpy-grid
                            http://stackoverflow.com/questions/6313308/get-all-the-diagonals-in-a-matrix-list-of-lists-in-python
                            http://stackoverflow.com/questions/2373306/pythonic-and-efficient-way-of-finding-adjacent-cells-in-grid

                        * Best at **Beginning of Game** and **Up to Level 3 of the Search Tree**
                          (beyond Level 3, symmetry is rare, and effort to check for it wasn't worthwhile)
                          (when Branching Factor is High,
                          i.e. Player 1 has 25 possible moves, but only 6 Unique moves,
                           since can use **Symmetry** about horiz, vert, diagonal axis, and
                           the center move)
                            * **Heuristic of Equivalent Moves by Rotating Board State 90 degrees**
                              (realising some moves equivalent)
                                * Reuse Game Tree known for Move (0,0) as is same as (4,0), (4,4), (0,4)
                                * Do not have to search the game tree further for these non-unique moves
                    * **Partitions** (know the game outcome as soon as get partition,
                    as separates both players completely, so player with longest path left Wins,
                    so avoid having to search to end of game tree)
                        * Best at **Beginning of Game** to create Partition
                          so your player is on side with most remaining moves
                    * **Avoid being Player 2**
                        * Note: Assuming both players play Optimally,
                          Player 2 always wins on 5x5 Isolation game
                    * **If Player 1, always first Move to Center square,
                        and then if possible use Reflection on all subsequent moves to win**
                        * **Reflection Phenomenon** is always copying the opponents move
                        180 degrees on other side of board, on every move they make
                            i.e.
                                Player 1 Move 1: Center
                                Player 2 Move 1: Diagonal
                                Player 1 Move 2: Opposite Diagonal, etc
                    * **If Player 2, detect if Player 1 is using Reflection Phenomonon and if
                      so, move to a position that Player 1 cannot reflect** (there are 8 such moves
                      of the 24 available to Player 2)
                    * **If Player 2, create Book of Opening Moves and Hints,
                    such as:**
                        * **If Player 1's first move is to Center Square, then Player 2's first
                        move afterward should be an Unreflectable position**
                        * **If Player 1's first move is NOT Center Square, then Player 2's first
                        move afterward should be the Center square**
                    * **After first moves,:
                        * **Load and Search our order
                          Order Book of Opening Moves and Hints efficiently, comprising**:
                            * Equivalent Moves
                            * Hash Tables
                        * Implement in order:
                            * **Minimax**
                            * **Iterative Deepening**
                            * **Alpha-Beta Pruning**
                            * **Evaluation Function**

        * Lesson 6.17 - 6.18
            * Multiplayer Games + MAXN (for any number of players)
                * 3-Player Isolation Game
                    * Last player able still able to move wins
                    * Pairs of players may form alliances
                    * Do Not use Minimax Algorithm in multi-player games
                    * Evaluate game board Leafs from perspective of
                    each player and propagate values (as triplets)
                    up the tree, i.e.
                        * Level 3 Max triplet from Player 3's perspective
                          (i.e. propagate up triplet leaf with largest Player 3 value
                        * Level 2 Max triplet from Player 2's "
                        * Level 1 Max triplet from Player 1's "
                        * Level 0 (Top) receives propagation from Level 1

        * Lesson 6.19
            * Multiplayer Games + Alpha-Beta Pruning
                * Lesson 6.21
                    * Reading:
                        * References: [Korf, 1991, Multi-player alpha-beta pruning](http://www.cc.gatech.edu/~thad/6601-gradAI-fall2015/Korf_Multi-player-Alpha-beta-Pruning.pdf)
                            * Why might alphabeta pruning only work well in the two player case?
                                *
                            * How does the size of the search tree change with more than two players?
                        * Questions Asked in Forum https://discussions.udacity.com/t/lesson-6-part-21-multi-player-alpha-beta-pruning-paper-reading-by-korf-figure-7-and-section-3-5/226209
                * A-B Pruning works if:
                    * Some players'
                      **Evaluation Functions** have an Upper Bound
                    * All players'
                    **Evaluation Functions** have a Lower Bound
                * **Evaluation Function** for number of #my_moves has:
                    * Lower Bound of 0
                    * Upper Bound - calculate using this **Evaluation Function**:
                        * **Evaluate Function** should sum of total number of
                        moves remaining for each player, which should not exceed
                        remaining number of empty squares on isolation board
                        (if 3x players, divide number of empty squares by 3 to get
                        moves remaining for each player).
                        Note: The Upper Bound would change with each game tree
                        Level.
                        * Simplify calculation that allows both
                          **Immediate Pruning** and **Shallow Pruning**,
                          BUT NOT **Deep Pruning** like before, and use
                          **3-Player MAX-MAX-MAX Pruning** (see Lesson 6.20):
                            * SUM of players scores (within a triplet group) must be Max of 10, i.e.
                                 * Level 2 Max triplet from Player 2's  perspective
                                 (i.e. if a Leaf has Player 2's [middle] value of 10 value
                                 where Player 1 and Player 3 value is 0 since Max SUM of all three is 10,
                                 then propagate up triplet Leaf with largest Player 2 value,
                                 and prune remaining leaves on that branch)
                                 * Level 0 (Top) receives ranges based on triplets propagated up,
                                  which gets refined on outcome of propagating up subsequent subtrees, i.e.
                                     (>=3, <=7, <=7)
                                 * When doing subsequent subtrees, apply the range
                                 to Level 1 (i.e. (>=3, <=7, <=7) ), and if the subsequent branches
                                 have player values already within those ranges but
                                 less than the player values we have propagated up
                                 in previous subtrees to Level 1, then Prune them

        * Lesson 6.22 Probabilistic Games
            * Stochastic Games (i.e. Backgammon)
                * Note: i.e. Moves limited on each turn, based on outcome of rolling two dice
                    (do not know value of each dice ahead of time, we assume we cannot
                    do a game tree for it, but we can)
                * Game Tree
                    * **Expectimax Algorithm** to make  Best Choice decisions on Moves
                        * Only allowed to Prune when have Known Bounds on the values that will be returned
                        by the Expectimax Function
                        * If player is going to lose anyway, unless the Opposition makes a
                         bad choice or is unlucky, then still use **Expectimax Algorithm**
                         to increase likelihood of winning incase Opposition makes
                         bad choice or is unlucky, BUT we would need to search all the way
                         to endgame
                        * When evaluating leaves, process highest leaf value first with highest probability
                        (change order) for the left-most branch

                * Sloppy Isolation (Variant of Isolation Game that is a Probabilistic Game)
                    * Add proability nodes between Levels to illustrate probability of
                    making the move vs a different move with probability of between 0 and 1
                    * Use #my_moves **Evaluation Function** at leaf nodes, if make move
                    at leaf node, calculate how many moves will still be available for the player
                    to move to after the oppositions next move, and for each leaf multiple this value
                    by the probability of that move occurring compared to others in the same branch,
                    then sum those values for each leaf node
                    * Elimate evaluating nodes all together if return is higher when looking for
                    Min Level

    * Project 2:
        * Goal: Program player that beats opponent consistently
        * Design different Heuristics to perform the Adversarial Search
        * Analyse and compare the performance of each Heuristic

        * Reference Projects by others:
            *
                ```
                https://github.com/morganel/AIND-Isolation-1
                https://github.com/bdiesel/AIND-Isolation
                https://github.com/ziyanfeng/AIND-Isolation
                https://github.com/davidventuri/udacity-aind/tree/master/isolation
                https://github.com/mohankarthik/AIND-P2-Isolation
                https://github.com/mlgill/AIND-Isolation
                https://github.com/morganel/AIND-Isolation-1
                ```

        * Reference Game Simulation https://deepmind.com/research/alphago/alphago-games-english/
        * Summary of AlphaGo, excellent https://www.tastehit.com/blog/google-deepmind-alphago-how-it-works/



* TODO ALL - http://redux.js.org/docs/introduction/